{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSNMN2T5Q2fu",
        "outputId": "c814b48a-5355-4cf1-bf7d-84a0ef22bb89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h97nxBMsRILq",
        "outputId": "101abeb9-9dfa-4baf-e133-2dd6ca860cce"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'numpy._core'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# 1Ô∏è‚É£ ‡πÇ‡∏´‡∏•‡∏î Scaler, Tokenizer, LabelEncoder\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutils/scaler.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 22\u001b[0m     scaler \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutils/tokenizer.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     25\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy._core'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.layers import Layer\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import re\n",
        "from collections import Counter\n",
        "import math\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# -------------------------\n",
        "# 1Ô∏è‚É£ ‡πÇ‡∏´‡∏•‡∏î Scaler, Tokenizer, LabelEncoder\n",
        "# -------------------------\n",
        "with open(\"utils/scaler.pkl\", \"rb\") as f:\n",
        "    scaler = pickle.load(f)\n",
        "\n",
        "with open(\"utils/tokenizer.pkl\", \"rb\") as f:\n",
        "    tokenizer = pickle.load(f)\n",
        "\n",
        "with open(\"utils/labelencoder.pkl\", \"rb\") as f:\n",
        "    le = pickle.load(f)\n",
        "\n",
        "maxlen = 200  # ‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ï‡∏≠‡∏ô train\n",
        "# -------------------------\n",
        "# 2Ô∏è‚É£ ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Custom Attention Layer\n",
        "# -------------------------\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class Attention(Layer):\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(shape=(input_shape[-1], input_shape[-1]),\n",
        "                                 initializer='glorot_uniform', trainable=True)\n",
        "        self.b = self.add_weight(shape=(input_shape[-1],), initializer='zeros', trainable=True)\n",
        "        self.u = self.add_weight(shape=(input_shape[-1], 1),\n",
        "                                 initializer='glorot_uniform', trainable=True)\n",
        "\n",
        "    def call(self, x):\n",
        "        u_it = tf.tanh(tf.tensordot(x, self.W, axes=1) + self.b)\n",
        "        a_it = tf.nn.softmax(tf.tensordot(u_it, self.u, axes=1), axis=1)\n",
        "        return tf.reduce_sum(x * a_it, axis=1)\n",
        "\n",
        "# -------------------------\n",
        "# 3Ô∏è‚É£ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏° custom_objects\n",
        "# -------------------------\n",
        "model = load_model(\"utils/model.keras\", custom_objects={\"Attention\": Attention})\n",
        "\n",
        "# -------------------------\n",
        "# 4Ô∏è‚É£ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô extract_url_features (‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏î‡πâ‡∏ß‡∏¢)\n",
        "\n",
        "# -------------------------\n",
        "\n",
        "BRAND_KEYWORDS = [\n",
        "    \"paypal\",\"apple\",\"amazon\",\"bank\",\"chase\",\"facebook\",\"meta\",\"google\",\"microsoft\",\n",
        "    \"outlook\",\"office365\",\"instagram\",\"line\",\"kbank\",\"scb\",\"krungsri\",\"kplus\"\n",
        "]\n",
        "\n",
        "COMMON_TLDS = set([\n",
        " \"com\",\"net\",\"org\",\"info\",\"biz\",\"co\",\"io\",\"ai\",\"app\",\"edu\",\"gov\",\"mil\",\"ru\",\"de\",\"uk\",\"cn\",\"fr\",\"jp\",\"br\",\"in\",\"it\",\"es\",\"au\",\"nl\",\"se\",\"no\"\n",
        "])\n",
        "\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "def parse_host_and_scheme(url: str): #‡∏î‡∏∂‡∏á host and scheme (http/https).\n",
        "    p = urlparse(url)\n",
        "    host = (p.hostname or \"\").lower()\n",
        "    scheme = (p.scheme or \"\").lower()\n",
        "    return host, scheme\n",
        "\n",
        "def is_ip_host(host: str): #if host is IP = 1.\n",
        "    return bool(re.fullmatch(r\"(?:\\d{1,3}\\.){3}\\d{1,3}\", host))\n",
        "\n",
        "def count_subdomains(host: str): #Counting subdomains.\n",
        "    if not host: return 0\n",
        "    return max(0, len(host.split(\".\")) - 2)\n",
        "\n",
        "def has_double_slash_in_path(url: str): #Check double slash \"//\" in the path.\n",
        "    return \"//\" in (urlparse(url).path or \"\")\n",
        "\n",
        "def has_tld_in_path(url: str): #Check TLD in path.\n",
        "    path = (urlparse(url).path or \"\").lower()\n",
        "    return any((\".\"+tld) in path for tld in COMMON_TLDS)\n",
        "\n",
        "def has_symbols_in_domain(host: str): #Check symbol in domain.\n",
        "    return bool(re.search(r\"[^a-z0-9\\.-]\", host))\n",
        "\n",
        "def domain_prefix_suffix_like_brand(host: str): #Check pattern where prefix/suffix might mimic brand.\n",
        "    if not host: return False\n",
        "    first = host.split(\".\")[0]\n",
        "    return any(b in first and \"-\" in first for b in BRAND_KEYWORDS)\n",
        "\n",
        "def brand_in_path_or_subdomain(host: str, url: str): #Check brand in path or subdomains.\n",
        "    text = (host + \" \" + urlparse(url).path + \" \" + urlparse(url).query).lower()\n",
        "    return any(b in text for b in BRAND_KEYWORDS)\n",
        "\n",
        "def digit_count_in_domain(host: str): #Check digit in domain\n",
        "    return sum(c.isdigit() for c in host)\n",
        "\n",
        "def url_entropy(url: str): #Check ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Ç‡∏≠‡∏á url\n",
        "    if not url:\n",
        "        return 0.0\n",
        "    counts = Counter(url)\n",
        "    total = len(url)\n",
        "    entropy = -sum((count/total) * math.log2(count/total) for count in counts.values())\n",
        "    return entropy\n",
        "\n",
        "def extract_url_features(url: str):\n",
        "    host, scheme = parse_host_and_scheme(url)\n",
        "    return {\n",
        "        \"is_ip_host\": int(is_ip_host(host)),\n",
        "        \"subdomain_count\": count_subdomains(host),\n",
        "        \"double_slash_in_path\": int(has_double_slash_in_path(url)),\n",
        "        \"tld_in_path\": int(has_tld_in_path(url)),\n",
        "        \"symbols_in_domain\": int(has_symbols_in_domain(host)),\n",
        "        \"prefix_suffix_like_brand\": int(domain_prefix_suffix_like_brand(host)),\n",
        "        \"brand_in_path_or_subdomain\": int(brand_in_path_or_subdomain(host, url)),\n",
        "        \"url_length\": len(url),\n",
        "        \"scheme_https\": 1 if scheme == \"https\" else 0,\n",
        "        \"digit_count_domain\": digit_count_in_domain(host),\n",
        "        \"url_entropy\": url_entropy(url)\n",
        "    }\n",
        "\n",
        "# -------------------------\n",
        "# 5Ô∏è‚É£ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô predict\n",
        "# -------------------------\n",
        "def predict_url(url):\n",
        "    # ‡πÅ‡∏õ‡∏•‡∏á structured features\n",
        "    struct_feat = scaler.transform([list(extract_url_features(url).values())])\n",
        "    # ‡πÅ‡∏õ‡∏•‡∏á text ‚Üí sequence\n",
        "    seq = pad_sequences(tokenizer.texts_to_sequences([url]), maxlen=maxlen)\n",
        "\n",
        "    # predict\n",
        "    pred = model.predict([seq, struct_feat])[0]\n",
        "    # convert index ‚Üí label\n",
        "    label = le.inverse_transform([np.argmax(pred)])[0]\n",
        "    return label, pred\n",
        "\n",
        "# -------------------------\n",
        "# 6Ô∏è‚É£ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô\n",
        "# -------------------------\n",
        "url_test = \"http://pantip.com/topic/40410662.com\"\n",
        "label, pred = predict_url(url_test)\n",
        "print(\"Label:\", label)\n",
        "print(\"Probabilities:\", pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uOd9wQRSYLs"
      },
      "outputs": [],
      "source": [
        "# --- Inlined utils (converted from phish_detector/utils.py) ---\n",
        "import re\n",
        "import math\n",
        "from collections import Counter\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "def parse_host_and_scheme(url):\n",
        "    try:\n",
        "        p = urlparse(url if '://' in url else 'http://' + url)\n",
        "        return p.hostname or '', p.scheme or 'http'\n",
        "    except:\n",
        "        return '', ''\n",
        "\n",
        "def is_ip_host(host):\n",
        "    return bool(re.match(r'^\\d+\\.\\d+\\.\\d+\\.\\d+$', host or ''))\n",
        "\n",
        "def count_subdomains(host):\n",
        "    if not host: return 0\n",
        "    parts = host.split('.')\n",
        "    return max(0, len(parts) - 2)\n",
        "\n",
        "def has_double_slash_in_path(url):\n",
        "    return '//' in urlparse(url if '://' in url else 'http://' + url).path\n",
        "\n",
        "def has_tld_in_path(url):\n",
        "    tlds = ['.com', '.net', '.org', '.co', '.io', '.gov']\n",
        "    path = urlparse(url if '://' in url else 'http://' + url).path.lower()\n",
        "    return any(t in path for t in tlds)\n",
        "\n",
        "def has_symbols_in_domain(host):\n",
        "    return bool(re.search(r'[^a-zA-Z0-9.-]', host or ''))\n",
        "\n",
        "def domain_prefix_suffix_like_brand(host):\n",
        "    return '-' in (host or '')\n",
        "\n",
        "def brand_in_path_or_subdomain(host, url):\n",
        "    brands = ['facebook','google','paypal','apple','microsoft','amazon','bank']\n",
        "    path = urlparse(url if '://' in url else 'http://' + url).path.lower()\n",
        "    subdomain = (host or '').split('.')[0].lower()\n",
        "    return any(b in path or b in subdomain for b in brands)\n",
        "\n",
        "def extract_html_features(html):\n",
        "    hrefs = re.findall(r'href=[\"\\'](.*?)[\"\\']', html or '', flags=re.IGNORECASE)\n",
        "    imgs = re.findall(r'<img[^>]+src=[\"\\'](.*?)[\"\\']', html or '', flags=re.IGNORECASE)\n",
        "    scripts = re.findall(r'<script[^>]+src=[\"\\'](.*?)[\"\\']', html or '', flags=re.IGNORECASE)\n",
        "    links_tag = re.findall(r'<link[^>]+href=[\"\\'](.*?)[\"\\']', html or '', flags=re.IGNORECASE)\n",
        "    forms = re.findall(r'<form[^>]+action=[\"\\'](.*?)[\"\\']', html or '', flags=re.IGNORECASE)\n",
        "    meta_keywords = re.findall(r'<meta[^>]+name=[\"\\']keywords[\"\\'][^>]+content=[\"\\'](.*?)[\"\\']', html or '', flags=re.IGNORECASE)\n",
        "    return {\n",
        "        'hrefs': hrefs,\n",
        "        'imgs': imgs,\n",
        "        'scripts': scripts,\n",
        "        'links_tag': links_tag,\n",
        "        'forms': forms,\n",
        "        'meta_keywords': meta_keywords\n",
        "    }\n",
        "\n",
        "def abnormal_links(hrefs):\n",
        "    for h in hrefs:\n",
        "        if h.strip().lower().startswith(('javascript:','mailto:','data:')):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def forms_action_abnormal(forms, host):\n",
        "    for a in forms:\n",
        "        if a and host not in a and not a.startswith('/') and not a.startswith('#'):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def anchors_point_elsewhere(hrefs, host):\n",
        "    count = 0\n",
        "    total = max(1, len(hrefs))\n",
        "    for h in hrefs:\n",
        "        if host and host not in h and h.startswith('http'):\n",
        "            count += 1\n",
        "    return (count / total) > 0.5\n",
        "\n",
        "def meta_keyword_mismatch(meta_keywords, host):\n",
        "    if not meta_keywords: return False\n",
        "    for kw in meta_keywords:\n",
        "        if host.split('.')[0] not in kw:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "# --- Extra Features ---\n",
        "def digit_count(url):\n",
        "    return sum(c.isdigit() for c in url)\n",
        "\n",
        "def url_length(url):\n",
        "    return len(url)\n",
        "\n",
        "def url_entropy(url):\n",
        "    prob = [freq/len(url) for freq in Counter(url).values()]\n",
        "    return -sum(p * math.log2(p) for p in prob)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DHeFc0QRQY2"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "def fetch_html(url):\n",
        "    try:\n",
        "        r = requests.get(url, timeout=5)\n",
        "        return r.text\n",
        "    except Exception as e:\n",
        "        print(\"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏î‡πâ:\", e)\n",
        "        return \"\"\n",
        "\n",
        "def phishing_score(url: str, html: str):\n",
        "    host, scheme = parse_host_and_scheme(url)\n",
        "    features = extract_html_features(html)\n",
        "    score = 0\n",
        "    reasons = []\n",
        "\n",
        "    if is_ip_host(host):\n",
        "        score += 2\n",
        "        reasons.append(\"Host ‡πÄ‡∏õ‡πá‡∏ô IP address\")\n",
        "    if count_subdomains(host) > 2:\n",
        "        score += 1\n",
        "        reasons.append(\"‡∏°‡∏µ subdomain ‡πÄ‡∏¢‡∏≠‡∏∞\")\n",
        "    if has_symbols_in_domain(host):\n",
        "        score += 1\n",
        "        reasons.append(\"‡∏°‡∏µ symbol ‡πÅ‡∏õ‡∏•‡∏Å‡πÉ‡∏ô domain\")\n",
        "    if domain_prefix_suffix_like_brand(host):\n",
        "        score += 2\n",
        "        reasons.append(\"‡∏ä‡∏∑‡πà‡∏≠ domain ‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢ brand ‡πÅ‡∏ï‡πà‡∏°‡∏µ -\")\n",
        "    if brand_in_path_or_subdomain(host, url):\n",
        "        score += 1\n",
        "        reasons.append(\"‡∏°‡∏µ brand keyword ‡πÉ‡∏ô path ‡∏´‡∏£‡∏∑‡∏≠ subdomain\")\n",
        "    if has_double_slash_in_path(url):\n",
        "        score += 1\n",
        "        reasons.append(\"path ‡∏°‡∏µ double slash\")\n",
        "    if has_tld_in_path(url):\n",
        "        score += 1\n",
        "        reasons.append(\"TLD ‡∏õ‡∏£‡∏≤‡∏Å‡∏è‡πÉ‡∏ô path\")\n",
        "    if abnormal_links(features['hrefs']):\n",
        "        score += 1\n",
        "        reasons.append(\"‡∏°‡∏µ‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥\")\n",
        "    if forms_action_abnormal(features['forms'], host):\n",
        "        score += 2\n",
        "        reasons.append(\"form action ‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥\")\n",
        "    if anchors_point_elsewhere(features['hrefs'], host):\n",
        "        score += 1\n",
        "        reasons.append(\"anchor ‡∏ä‡∏µ‡πâ‡πÑ‡∏õ‡πÄ‡∏ß‡πá‡∏ö‡∏≠‡∏∑‡πà‡∏ô‡πÄ‡∏¢‡∏≠‡∏∞\")\n",
        "    if meta_keyword_mismatch(features['meta_keywords'], host):\n",
        "        score += 1\n",
        "        reasons.append(\"meta keywords ‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö host\")\n",
        "\n",
        "    #new features\n",
        "    dcount = digit_count(url)\n",
        "    ulen = url_length(url)\n",
        "    uentropy = url_entropy(url)\n",
        "\n",
        "    if dcount > 5:\n",
        "        score += 1\n",
        "        reasons.append(f\"‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÄ‡∏¢‡∏≠‡∏∞ (digits={dcount})\")\n",
        "    if ulen > 75:\n",
        "        score += 1\n",
        "        reasons.append(f\"URL ‡∏¢‡∏≤‡∏ß‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥ (length={ulen})\")\n",
        "    if uentropy > 4.0:\n",
        "        score += 1\n",
        "        reasons.append(f\"Entropy ‡∏Ç‡∏≠‡∏á URL ‡∏™‡∏π‡∏á (entropy={uentropy:.2f})\")\n",
        "\n",
        "    # add into features dict\n",
        "    features.update({\n",
        "        \"digit_count\": dcount,\n",
        "        \"url_length\": ulen,\n",
        "        \"url_entropy\": uentropy\n",
        "    })\n",
        "\n",
        "    return score, reasons, features, host, scheme\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_cYxsQxRoTF",
        "outputId": "935c4864-74d8-4318-9b24-f70ce35c549d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîë Enter your OpenAI API key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "from getpass import getpass\n",
        "\n",
        "# Secure API key\n",
        "\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJWWA3TCSD9L"
      },
      "outputs": [],
      "source": [
        "def prepare_llm_prompt(url, host, scheme, bilstm_result, bilstm_prob, score, reasons, features):\n",
        "    return f\"\"\"\n",
        "‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πàmodel BiLSTM ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏≤‡∏Å URL: {bilstm_result} (probability={bilstm_prob:.2f})\n",
        "\n",
        "‡πÇ‡∏î‡∏¢‡∏ä‡πà‡∏ß‡∏¢‡∏Ñ‡∏¥‡∏î‡∏à‡∏≤‡∏Å feature ‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏°‡∏≤‡πÑ‡∏î‡πâ‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:\n",
        "- Heuristic score: {score}\n",
        "- Reasons: {', '.join(reasons)}\n",
        "\n",
        "Features extracted:\n",
        "- Digit count: {features.get('digit_count')}\n",
        "- URL length: {features.get('url_length')}\n",
        "- URL entropy: {features.get('url_entropy'):.2f}\n",
        "- Hrefs: {features['hrefs']}\n",
        "- Images: {features['imgs']}\n",
        "- Scripts: {features['scripts']}\n",
        "- Links tag: {features['links_tag']}\n",
        "- Forms: {features['forms']}\n",
        "- Meta keywords: {features['meta_keywords']}\n",
        "\n",
        "‡πÇ‡∏õ‡∏£‡∏î‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏™‡∏±‡πâ‡∏ô ‡πÜ ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡∏∏‡∏õ‡∏ß‡πà‡∏≤ 'Likely Phishing' ‡∏´‡∏£‡∏∑‡∏≠ 'Likely Safe'\n",
        "\"\"\"\n",
        "\n",
        "def analyze_with_llm(prompt: str):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqRashPPSEUM"
      },
      "outputs": [],
      "source": [
        "# ‡∏™‡∏°‡∏°‡∏ï‡∏¥ bilstm_prob ‡πÄ‡∏õ‡πá‡∏ô array ‡πÄ‡∏ä‡πà‡∏ô [0.2, 0.8] ‡πÅ‡∏™‡∏î‡∏á probability ‡∏Ç‡∏≠‡∏á [Safe, Phishing]\n",
        "# ‡πÄ‡∏£‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å class index ‡∏ï‡∏≤‡∏°‡∏ú‡∏•‡∏Ç‡∏≠‡∏á bilstm_result\n",
        "import numpy as np\n",
        "\n",
        "def run_analysis_on_url(url, call_llm=True):\n",
        "    html = fetch_html(url)\n",
        "    score, reasons, features, host, scheme = phishing_score(url, html)\n",
        "\n",
        "    # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å BiLSTM predict\n",
        "    bilstm_result, bilstm_prob_array = predict_url(url)  # ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì\n",
        "    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô float scalar: ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å class ‡∏ï‡∏≤‡∏°‡∏ú‡∏•\n",
        "    class_idx = 0 if bilstm_result == \"Likely Safe\" else 1\n",
        "    bilstm_prob = float(np.array(bilstm_prob_array)[class_idx])\n",
        "\n",
        "    if call_llm:\n",
        "        prompt = prepare_llm_prompt(url, host, scheme, bilstm_result, bilstm_prob, score, reasons, features)\n",
        "        result = analyze_with_llm(prompt)\n",
        "        print(\"\\n------ Phishing Analysis (LLM) ------\")\n",
        "        print(result)\n",
        "    else:\n",
        "        result = None\n",
        "        print(\"\\n------ Rule-based Analysis Only ------\")\n",
        "        print(f\"Rule-based score: {score}\")\n",
        "        print(f\"Reasons: {', '.join(reasons)}\")\n",
        "\n",
        "    return {\n",
        "        \"result\": result,\n",
        "        \"score\": score,\n",
        "        \"reasons\": reasons,\n",
        "        \"features\": features,\n",
        "        \"host\": host,\n",
        "        \"scheme\": scheme\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEfuMCzZSGh7",
        "outputId": "68ed7043-6d29-44df-bef5-1022b0e846a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "------ Phishing Analysis (LLM) ------\n",
            "‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤ ‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡∏∏‡∏õ‡πÑ‡∏î‡πâ‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:\n",
            "\n",
            "1. **Heuristic Score**: ‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô 2 ‡πÅ‡∏™‡∏î‡∏á‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏ö‡πâ‡∏≤‡∏á ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å\n",
            "2. **Reasons**: \n",
            "   - ‡∏°‡∏µ subdomain ‡πÄ‡∏¢‡∏≠‡∏∞: ‡∏Å‡∏≤‡∏£‡∏°‡∏µ subdomain ‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏≠‡∏≤‡∏à‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏ö‡∏™‡∏ô‡πÅ‡∏•‡∏∞‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏Ç‡∏≠‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢\n",
            "   - Meta keywords ‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö host: ‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà meta keywords ‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö host ‡∏≠‡∏≤‡∏à‡∏ö‡πà‡∏á‡∏ö‡∏≠‡∏Å‡∏ñ‡∏∂‡∏á‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏´‡∏•‡∏≠‡∏Å‡∏•‡∏ß‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ\n",
            "\n",
            "3. **Features**:\n",
            "   - URL length: 34 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£ ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÑ‡∏°‡πà‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ\n",
            "   - URL entropy: 3.98 ‡πÅ‡∏™‡∏î‡∏á‡∏ñ‡∏∂‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Ç‡∏≠‡∏á URL ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å\n",
            "   - Hrefs, Images, Scripts: ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏ó‡∏µ‡πà‡∏î‡∏π‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏≠‡∏á‡∏à‡∏£‡∏¥‡∏á (mycourses.ict.mahidol.ac.th) ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏ó‡∏µ‡πà‡∏î‡∏µ\n",
            "   - Forms: ‡∏°‡∏µ‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á\n",
            "\n",
            "**‡∏™‡∏£‡∏∏‡∏õ**: ‡πÅ‡∏°‡πâ‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏°‡∏µ‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏ö‡∏≤‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏ö‡πà‡∏á‡∏ö‡∏≠‡∏Å‡∏ñ‡∏∂‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á (‡πÄ‡∏ä‡πà‡∏ô subdomain ‡πÄ‡∏¢‡∏≠‡∏∞‡πÅ‡∏•‡∏∞ meta keywords ‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á) ‡πÅ‡∏ï‡πà‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°‡πÅ‡∏•‡πâ‡∏ß URL ‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏ó‡∏µ‡πà‡∏î‡∏π‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢\n",
            "\n",
            "**‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö**: Likely Safe\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'result': '‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤ ‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡∏∏‡∏õ‡πÑ‡∏î‡πâ‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:\\n\\n1. **Heuristic Score**: ‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô 2 ‡πÅ‡∏™‡∏î‡∏á‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏ö‡πâ‡∏≤‡∏á ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å\\n2. **Reasons**: \\n   - ‡∏°‡∏µ subdomain ‡πÄ‡∏¢‡∏≠‡∏∞: ‡∏Å‡∏≤‡∏£‡∏°‡∏µ subdomain ‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏≠‡∏≤‡∏à‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏ö‡∏™‡∏ô‡πÅ‡∏•‡∏∞‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏Ç‡∏≠‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢\\n   - Meta keywords ‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö host: ‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà meta keywords ‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö host ‡∏≠‡∏≤‡∏à‡∏ö‡πà‡∏á‡∏ö‡∏≠‡∏Å‡∏ñ‡∏∂‡∏á‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏´‡∏•‡∏≠‡∏Å‡∏•‡∏ß‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ\\n\\n3. **Features**:\\n   - URL length: 34 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£ ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÑ‡∏°‡πà‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ\\n   - URL entropy: 3.98 ‡πÅ‡∏™‡∏î‡∏á‡∏ñ‡∏∂‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Ç‡∏≠‡∏á URL ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å\\n   - Hrefs, Images, Scripts: ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏ó‡∏µ‡πà‡∏î‡∏π‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏≠‡∏á‡∏à‡∏£‡∏¥‡∏á (mycourses.ict.mahidol.ac.th) ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏ó‡∏µ‡πà‡∏î‡∏µ\\n   - Forms: ‡∏°‡∏µ‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á\\n\\n**‡∏™‡∏£‡∏∏‡∏õ**: ‡πÅ‡∏°‡πâ‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏°‡∏µ‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏ö‡∏≤‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏ö‡πà‡∏á‡∏ö‡∏≠‡∏Å‡∏ñ‡∏∂‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á (‡πÄ‡∏ä‡πà‡∏ô subdomain ‡πÄ‡∏¢‡∏≠‡∏∞‡πÅ‡∏•‡∏∞ meta keywords ‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á) ‡πÅ‡∏ï‡πà‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°‡πÅ‡∏•‡πâ‡∏ß URL ‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏ó‡∏µ‡πà‡∏î‡∏π‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢\\n\\n**‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö**: Likely Safe',\n",
              " 'score': 2,\n",
              " 'reasons': ['‡∏°‡∏µ subdomain ‡πÄ‡∏¢‡∏≠‡∏∞', 'meta keywords ‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö host'],\n",
              " 'features': {'hrefs': ['https://mycourses.ict.mahidol.ac.th/pluginfile.php/1/core_admin/favicon/64x64/1757921059/favicon.ico',\n",
              "   'https://mycourses.ict.mahidol.ac.th/theme/yui_combo.php?rollup/3.18.1/yui-moodlesimple-min.css',\n",
              "   'https://mycourses.ict.mahidol.ac.th/theme/styles.php/boost/1757921059_1/all',\n",
              "   '#maincontent',\n",
              "   'https://mycourses.ict.mahidol.ac.th/login/forgot_password.php',\n",
              "   'https://mycourses.ict.mahidol.ac.th/auth/saml2/login.php?wants=https%3A%2F%2Fmycourses.ict.mahidol.ac.th%2F&amp;idp=333b5ee96be2a2062bb8ca7793f7212d&amp;passive=off',\n",
              "   'https://mycourses.ict.mahidol.ac.th/admin/tool/dataprivacy/summary.php',\n",
              "   'https://mycourses.ict.mahidol.ac.th/admin/tool/policy/viewall.php?returnurl=https%3A%2F%2Fmycourses.ict.mahidol.ac.th%2Flogin%2Findex.php',\n",
              "   'https://download.moodle.org/mobile?version=2024100705&amp;lang=en&amp;iosappid=633359593&amp;androidappid=com.moodle.moodlemobile',\n",
              "   'https://moodle.com'],\n",
              "  'imgs': ['https://mycourses.ict.mahidol.ac.th/pluginfile.php/1/core_admin/logo/0x200/1757921059/MUICT2.png',\n",
              "   'https://mycourses.ict.mahidol.ac.th/theme/image.php/boost/core/1757921059/i/user'],\n",
              "  'scripts': ['https://mycourses.ict.mahidol.ac.th/lib/javascript.php/1757921059/lib/polyfills/polyfill.js',\n",
              "   'https://mycourses.ict.mahidol.ac.th/theme/yui_combo.php?rollup/3.18.1/yui-moodlesimple-min.js',\n",
              "   'https://mycourses.ict.mahidol.ac.th/lib/javascript.php/1757921059/lib/javascript-static.js',\n",
              "   'https://mycourses.ict.mahidol.ac.th/lib/javascript.php/1757921059/lib/requirejs/require.min.js',\n",
              "   'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=MML_HTMLorMML%22&amp;delayStartupUntil=configured'],\n",
              "  'links_tag': ['https://mycourses.ict.mahidol.ac.th/pluginfile.php/1/core_admin/favicon/64x64/1757921059/favicon.ico',\n",
              "   'https://mycourses.ict.mahidol.ac.th/theme/yui_combo.php?rollup/3.18.1/yui-moodlesimple-min.css',\n",
              "   'https://mycourses.ict.mahidol.ac.th/theme/styles.php/boost/1757921059_1/all'],\n",
              "  'forms': ['https://mycourses.ict.mahidol.ac.th/login/index.php'],\n",
              "  'meta_keywords': ['moodle, Log in to the site | ICT My Courses'],\n",
              "  'digit_count': 0,\n",
              "  'url_length': 34,\n",
              "  'url_entropy': 3.984234164652488},\n",
              " 'host': 'mycourses.ict.mahidol.ac.th',\n",
              " 'scheme': 'http'}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res = run_analysis_on_url(\"http://mycourses.ict.mahidol.ac.th\", call_llm=True)\n",
        "res"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "muict",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
